### ğŸ“¦ å®Œæ•´ `streamlit_app.py`

```python
import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import re
import os

FDA_URL = "https://www.fda.gov/drugs/drug-safety-and-availability/drug-safety-communications"

# ---------- è³‡æ–™æ¸…ç†èˆ‡æ­£è¦åŒ– ----------

def clean_text(s):
    return re.sub(r"\s+", " ", str(s)).strip().lower()

def normalize_brand(s):
    s = clean_text(s)
    s = re.sub(r"\b(tablets?|capsules?|injection|solution|concentrate|for infusion|pre-filled syringe)\b", "", s)
    return re.sub(r"[^\w\s]", "", s).strip()

SYNONYMS = {
    "hyoscine": "scopolamine",
    "scopolamine butylbromide": "scopolamine",
    "hyoscine n butylbromide": "scopolamine",
    "glatiramer": "glatiramer acetate",
    "lecanemab": "lecanemab",
    "clozapine": "clozapine",
    "cetirizine": "cetirizine",
    "levocetirizine": "levocetirizine",
    "methylphenidate": "methylphenidate",
    "amphetamine": "amphetamine",
}

def normalize_ingredient_token(tok):
    tok = clean_text(tok)
    for salt in ["hbr", "bromide", "acetate", "tartrate", "hcl", "maleate", "methylsulfate"]:
        tok = tok.replace(salt, "")
    tok = re.sub(r"[^\w\s]", "", tok).strip()
    return SYNONYMS.get(tok, tok)

def split_ingredients(s):
    parts = re.split(r";|,|/| and |\+|\|", str(s))
    return list({normalize_ingredient_token(p) for p in parts if p.strip()})

def ingredient_match(fda_list, tw_list):
    return bool(set(fda_list) & set(tw_list))

# ---------- FDA æŠ“å–èˆ‡è§£æ ----------

def fetch_html(url):
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
    r = requests.get(url, headers=headers, timeout=30)
    r.raise_for_status()
    return r.text

def parse_current_list(html):
    soup = BeautifulSoup(html, "html.parser")
    header = soup.find(lambda tag: tag.name in ["h2", "h3"] and "Current Drug Safety Communications" in tag.text)
    items = []
    if header:
        for a in header.find_next().find_all("a", href=True):
            txt = a.get_text(strip=True)
            m = re.match(r"(\d{2}[-/]\d{2}[-/]\d{4})\s+(.*)", txt)
            if m:
                date = m.group(1).replace("/", "-")
                title = m.group(2)
                href = a["href"]
                items.append({"date": date, "title": title, "href": href})
    return items

def extract_fields(title):
    t = title.lower()
    ingr = re.findall(r"\(([^)]+)\)", t)
    product = re.split(r"\(|-", title)[0].strip()
    return {
        "product": product,
        "ingredient_raw": ingr[0] if ingr else ""
    }

def build_fda_df(items):
    if not items:
        return pd.DataFrame(columns=["æ—¥æœŸ","å“å","ä¸»æˆåˆ†","å®‰å…¨è­°é¡Œ","ç”¨è—¥æ—ç¾¤","æ³¨æ„äº‹é …èˆ‡å°ç­–","source_title","source_url"])
    rows = []
    for it in items:
        fields = extract_fields(it["title"])
        ingr_list = split_ingredients(fields["ingredient_raw"])
        rows.append({
            "æ—¥æœŸ": it["date"],
            "å“å": fields["product"],
            "ä¸»æˆåˆ†": ", ".join(ingr_list),
            "å®‰å…¨è­°é¡Œ": "",
            "ç”¨è—¥æ—ç¾¤": "",
            "æ³¨æ„äº‹é …èˆ‡å°ç­–": "",
            "source_title": it["title"],
            "source_url": it["href"]
        })
    return pd.DataFrame(rows)

def fallback_seed():
    return pd.DataFrame([
        {"æ—¥æœŸ":"2025-08-28","å“å":"Leqembi","ä¸»æˆåˆ†":"lecanemab","å®‰å…¨è­°é¡Œ":"å»ºè­°æ›´æ—© MRI ç›£æ¸¬","ç”¨è—¥æ—ç¾¤":"é˜¿èŒ²æµ·é»˜ç—‡æ‚£è€…","æ³¨æ„äº‹é …èˆ‡å°ç­–":"èª¿æ•´ MRI é »ç‡","source_title":"Leqembi (lecanemab)","source_url":FDA_URL},
        {"æ—¥æœŸ":"2025-08-27","å“å":"Clozapine","ä¸»æˆåˆ†":"clozapine","å®‰å…¨è­°é¡Œ":"ç§»é™¤ REMS è¨ˆç•«","ç”¨è—¥æ—ç¾¤":"ç²¾ç¥åˆ†è£‚ç—‡æ‚£è€…","æ³¨æ„äº‹é …èˆ‡å°ç­–":"ä¾æ–°æ¨™ç¤ºèª¿æ•´ç›£æ¸¬","source_title":"Clozapine","source_url":FDA_URL},
        {"æ—¥æœŸ":"2025-08-11","å“å":"Copaxone","ä¸»æˆåˆ†":"glatiramer acetate","å®‰å…¨è­°é¡Œ":"éæ•æ€§ä¼‘å…‹è­¦ç¤º","ç”¨è—¥æ—ç¾¤":"å¤šç™¼æ€§ç¡¬åŒ–ç—‡æ‚£è€…","æ³¨æ„äº‹é …èˆ‡å°ç­–":"å‡ºç¾éæ•å¾µå…†ç«‹å³åœè—¥","source_title":"Copaxone (glatiramer acetate)","source_url":FDA_URL},
        {"æ—¥æœŸ":"2025-08-18","å“å":"Transderm ScÅp","ä¸»æˆåˆ†":"scopolamine","å®‰å…¨è­°é¡Œ":"é«˜æº«ä½µç™¼ç—‡é¢¨éšª","ç”¨è—¥æ—ç¾¤":"ä½¿ç”¨æŠ—æšˆè²¼ç‰‡è€…","æ³¨æ„äº‹é …èˆ‡å°ç­–":"é«˜æº«ç’°å¢ƒæ…ç”¨","source_title":"Transderm ScÅp (scopolamine)","source_url":FDA_URL},
    ])

# ---------- å°ç£ CSV è¼‰å…¥ ----------

@st.cache_data
def load_tw_data():
    path = os.path.join(os.path.dirname(__file__), "37_2c.csv")
    df = pd.read_csv(path)
    df["tw_e_brand_norm"] = df["tw_e_brand"].apply(normalize_brand)
    df["tw_ing_list"] = df["tw_ingredient"].apply(split_ingredients)
    return df

# ---------- æ¯”å°é‚è¼¯ ----------

def match_tw_products(fda_df, tw_df):
    matches = []
    for _, row in fda_df.iterrows():
        fda_brand = normalize_brand(row["å“å"])
        fda_ing = split_ingredients(row["ä¸»æˆåˆ†"])
        brand_hits = tw_df[tw_df["tw_e_brand_norm"] == fda_brand]
        ing_hits = tw_df[tw_df["tw_ing_list"].apply(lambda lst: ingredient_match(fda_ing, lst))]
        hit_df = pd.concat([brand_hits, ing_hits]).drop_duplicates(subset=["tw_id"])
        for _, tw in hit_df.iterrows():
            matches.append({
                "æ—¥æœŸ": row["æ—¥æœŸ"],
                "FDA_å“å": row["å“å"],
                "FDA_ä¸»æˆåˆ†": row["ä¸»æˆåˆ†"],
                "è—¥è­‰è™Ÿç¢¼": tw["tw_id"],
                "ä¸­æ–‡å“å": tw["tw_c_brand"],
                "è‹±æ–‡å“å": tw["tw_e_brand"],
                "åŠ‘å‹": tw["tw_form"],
                "ä¸»æˆåˆ†": tw["tw_ingredient"],
                "è—¥å•†": tw["tw_company"],
            })
    return pd.DataFrame(matches)

# ---------- Streamlit UI ----------

st.set_page_config(page_title="FDA é€šå ±è§£æèˆ‡å°ç£å“é …æ¯”å°", layout="wide")
st.title("ğŸ’Š FDA è—¥å“å®‰å…¨é€šå ±è§£æèˆ‡å°ç£å“é …æ¯”å°")

st.info("æ­£åœ¨æŠ“å– FDA é€šå ±è³‡æ–™â€¦")
try:
    html = fetch_html(FDA_URL)
    items = parse_current_list(html)
    fda_df = build_fda_df(items)
    if fda_df.empty:
        st.warning("âš ï¸ FDA ç¶²é è§£æå¤±æ•—ï¼Œå·²è¼‰å…¥ 2025 ç¨®å­è³‡æ–™ã€‚")
        fda_df = fallback_seed()
    else:
        st.success(f"å·²è§£æ FDA é€šå ± {len(fda_df)} ç­†")
except Exception as e:
    st.error(f"FDA ç¶²é æŠ“å–å¤±æ•—ï¼š{e}")
    fda_df = fallback_seed()

st.subheader("FDA Current Drug Safety Communications")
cols = [c for c in ["æ—¥æœŸ","å“å","ä¸»æˆåˆ†","source_title"] if c in fda_df.columns]
st.dataframe(fda_df[cols], use_container_width=True)

st.info("æ­£åœ¨è¼‰å…¥å°ç£å“é …è³‡æ–™â€¦")
try:
    tw_df = load_tw_data()
    st.success(f"å·²è¼‰å…¥å°ç£å“é … {len(tw_df)} ç­†")
except Exception as e:
    st.error(f"CSV è¼‰å…¥å¤±æ•—ï¼š{e}")
    tw_df = pd.DataFrame()

if not fda_df.empty and not tw_df.empty:
    match_df = match_tw_products(fda_df, tw_df)
    st.subheader(f"âœ… æˆåŠŸæ¯”å°çµæœï¼ˆ{len(match_df)} ç­†ï¼‰")
    st.dataframe(match_df[
        ["æ—¥æœŸ","FDA_å“å","FDA_ä¸»æˆåˆ†","è—¥è­‰è™Ÿç¢¼","ä¸­æ–‡å“å","è‹±æ–‡å“å","åŠ‘å‹","ä¸»æˆåˆ†","è—¥å•†"]
    ], use_container_width=True)

    matched_keys = set(zip(match_df["æ—¥æœŸ"], match_df["FDA_å“å"], match_df["FDA_ä¸»æˆåˆ†"]))
    unmatched = fda_df[~fda_df.apply(lambda r: (r["æ—¥æœŸ"], r["å“å"], r["ä¸»æˆåˆ†"]) in matched_keys, axis=1)]
    st.subheader(f"âš ï¸ æœªåŒ¹é… FDA é€šå ±ï¼ˆ{len(unmatched)} ç­†ï¼‰")
    st.dataframe(unmatched[["æ—¥æœŸ","å“å","ä¸»æˆåˆ†","source_title"]], use_container_width=True)

    relevant_tokens = set()
    for ing in fda_df["ä¸»æˆåˆ†"].dropna():
        relevant_tokens.update(split_ingredients(ing))
    cand_tw = tw_df[tw_df["tw_ing_list"].apply(lambda lst: bool(set(lst) & relevant_tokens))]
    st.subheader(f"ğŸ” å¯èƒ½ç›¸é—œå°ç£å“é …ï¼ˆ{len(cand_tw)} ç­†ï¼‰")
    st.dataframe(cand_tw[
        ["tw_id","tw_c_brand","tw_e_brand","tw_form","tw_ingredient","tw_company"]
    ], use_container_width=True)
